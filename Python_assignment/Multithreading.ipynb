{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adeebkhan0706/pwskillsassignmnets/blob/main/Multithreading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multithreading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ItCnUoLPrUq"
      },
      "source": [
        "## **Q1. What is multithreading in python? Why is it used? Name the module used to handle threads in python**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgOF1rAOfFnu"
      },
      "source": [
        "Multithreading in Python refers to the capability of a program to execute multiple threads concurrently. A thread is a lightweight unit of execution within a process, and multithreading allows multiple threads to run concurrently, sharing the same resources of a single process.\n",
        "\n",
        "Multithreading is used to achieve concurrency in Python programs. It allows you to perform multiple tasks simultaneously, thus improving the overall performance and responsiveness of the application. By utilizing multiple threads, you can execute computationally intensive tasks, perform I/O operations, or handle multiple client requests efficiently.\n",
        "\n",
        "In Python, the threading module is commonly used to handle threads. It provides a high-level interface for creating and managing threads in Python programs. The threading module allows you to create threads, start them, synchronize their execution, and communicate between them using various synchronization primitives like locks, events, conditions, and queues. It simplifies the process of working with threads and provides a convenient way to incorporate multithreading into your Python applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDu-H8rsPrSG"
      },
      "source": [
        "## **Q2. Why threading module used? Write the use of the following functions**\n",
        "  1. activeCount()\n",
        "  2. currentThread()\n",
        "  3. enumerate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7DF2tyDg-Fx"
      },
      "source": [
        "The threading module in Python is used for various purposes related to multithreading. Here are some of the key reasons why the threading module is used:\n",
        "\n",
        "1. Creating and managing threads: The threading module provides a high-level interface to create and manage threads in Python. It offers a Thread class that you can subclass to create new threads, start them, and control their execution.\n",
        "\n",
        "2. Concurrency and parallelism: The threading module allows you to achieve concurrency by executing multiple threads concurrently. This enables you to perform multiple tasks simultaneously, improving the overall performance of your application. By utilizing multiple CPU cores, you can also achieve parallelism, where multiple threads are executed in parallel to speed up computationally intensive tasks.\n",
        "\n",
        "3. Synchronization: When multiple threads access shared resources, synchronization is necessary to prevent data corruption and ensure thread safety. The threading module provides various synchronization primitives like locks, events, conditions, and semaphores, which help you control the execution of threads, coordinate their activities, and prevent race conditions.\n",
        "\n",
        "4. Communication between threads: Threads often need to communicate and share data with each other. The threading module provides built-in mechanisms like queues and shared variables to facilitate communication between threads. Queues, such as Queue and Deque, allow safe data exchange between threads, while shared variables, such as Value and Array, provide a way to share data in a controlled manner.\n",
        "\n",
        "5. Thread-based parallelism in I/O-bound tasks: Python's Global Interpreter Lock (GIL) prevents true parallel execution of threads in CPU-bound tasks. However, threads can still provide performance benefits in I/O-bound tasks, such as network requests or disk operations, where the GIL is released during I/O operations. The threading module enables you to leverage thread-based parallelism in such scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oh8ZT1phhMN"
      },
      "source": [
        "use of the three functions\n",
        "1. activeCount(): The activeCount() function is a method provided by the threading module in Python. It returns the number of Thread objects currently alive. This function is useful when you need to keep track of the number of active threads in your program. It allows you to monitor the progress or status of your threads and make decisions based on the number of active threads. For example, you can use activeCount() to determine if all your threads have completed their tasks before proceeding to the next step in your program.\n",
        "\n",
        "2. currentThread(): The currentThread() function is another method provided by the threading module. It returns the current Thread object corresponding to the caller's thread of execution. This function is primarily used to access and manipulate the properties and behavior of the current thread. You can use currentThread() to obtain information about the current thread, such as its name, identifier, or thread-local data. Additionally, it allows you to perform operations like setting the thread name or modifying thread-specific data associated with the current thread.\n",
        "\n",
        "3. enumerate(): The enumerate() function is a built-in function in Python that is often used in conjunction with the threading module. It returns a list of all Thread objects currently alive. This function is helpful when you need to iterate over all the active threads in your program and perform operations on each thread individually. You can use enumerate() to obtain a list of active threads, and then access their properties or invoke thread-specific methods. It allows you to perform tasks like monitoring the status of all threads, terminating specific threads, or collecting information about each thread's progress."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kIYR2GoPrP6"
      },
      "source": [
        "## **Q3. Expain the following functions:**\n",
        "  1. run()\n",
        "  2. start()\n",
        "  3. join()\n",
        "  4. isAlive()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKovXse7jBbI"
      },
      "source": [
        "1. run(): The run() method is a function provided by the Thread class in the threading module. It represents the entry point for the thread's execution logic. When you create a new thread by subclassing the Thread class and overriding its run() method, the code written inside the run() method defines the actions and tasks that the thread will perform. You need to override this method and implement the desired functionality for your thread. When you start the thread using the start() method, the run() method is automatically invoked, and the thread starts executing its defined logic.\n",
        "\n",
        "2. start(): The start() method is used to start the execution of a thread. It is provided by the Thread class in the threading module. When you call the start() method on a Thread object, it initiates the execution of the thread's run() method in a separate thread of control. The start() method performs necessary setup tasks and then schedules the thread for execution by the Python interpreter. Once the start() method is called, the thread enters the \"runnable\" state and is eligible for execution by the interpreter's thread scheduler. It is important to note that you should not directly call the run() method to start a thread; instead, use start().\n",
        "\n",
        "3. join(): The join() method is a function provided by the Thread class in the threading module. It allows one thread to wait for the completion of another thread. When you call join() on a Thread object, the calling thread is blocked and waits until the target thread completes its execution. This method is useful when you want to ensure that the main thread (or any other thread) waits for a specific thread to finish before proceeding further. By using join(), you can synchronize the execution of threads and ensure that they complete their tasks in the desired order.\n",
        "\n",
        "4. isAlive(): The isAlive() method is a function provided by the Thread class in the threading module. It allows you to check whether a thread is currently alive or active. When you call isAlive() on a Thread object, it returns True if the thread is currently executing or is in the process of being started. Conversely, it returns False if the thread has completed its execution or hasn't started yet. This method is helpful when you need to check the status of a thread and make decisions based on whether it is still running or has completed its task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1cZ4yO6PrNe"
      },
      "source": [
        "## **Q4. Write a program to create two threads. Thread one must print the list of squares and thread two must print the list of cubes.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtlQbaHNkE8Y",
        "outputId": "0474809d-19df-4765-fe2e-798ce6403ef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Square of 1: 1\n",
            "Square of 2: 4\n",
            "Square of 3: 9\n",
            "Square of 4: 16\n",
            "Square of 5: 25\n",
            "Square of 6: 36\n",
            "Square of 7: 49\n",
            "Square of 8: 64\n",
            "Square of 9: 81Cube of 1: 1\n",
            "Cube of 2: 8\n",
            "Cube of 3: 27\n",
            "Cube of 4: 64\n",
            "Cube of 5: 125\n",
            "Cube of 6: 216\n",
            "Cube of 7: 343\n",
            "Cube of 8: 512\n",
            "Cube of 9: 729\n",
            "Cube of 10: 1000\n",
            "\n",
            "Square of 10: 100\n",
            "Program completed.\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "\n",
        "def print_squares():\n",
        "    for i in range(1, 11):\n",
        "        square = i ** 2\n",
        "        print(f\"Square of {i}: {square}\")\n",
        "\n",
        "def print_cubes():\n",
        "    for i in range(1, 11):\n",
        "        cube = i ** 3\n",
        "        print(f\"Cube of {i}: {cube}\")\n",
        "\n",
        "# Create the first thread for printing squares\n",
        "thread1 = threading.Thread(target=print_squares)\n",
        "\n",
        "# Create the second thread for printing cubes\n",
        "thread2 = threading.Thread(target=print_cubes)\n",
        "\n",
        "# Start both threads\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "# Wait for both threads to finish\n",
        "thread1.join()\n",
        "thread2.join()\n",
        "\n",
        "print(\"Program completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgx22k4TPrK0"
      },
      "source": [
        "## **Q5. State advantages and disadvantages of multithreading.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrbC_WXDl3vI"
      },
      "source": [
        "Advantages of Multithreading:\n",
        "\n",
        "1. Concurrency: Multithreading allows concurrent execution of multiple threads within a single process. This enables performing multiple tasks simultaneously, leading to improved overall performance and responsiveness of an application. It maximizes CPU utilization by utilizing idle CPU time during I/O operations or waiting periods.\n",
        "\n",
        "2. Responsiveness: Multithreading enhances the responsiveness of an application by keeping it interactive and preventing it from becoming unresponsive or frozen. By offloading time-consuming tasks to separate threads, the main thread remains available to handle user interactions and respond promptly.\n",
        "\n",
        "3. Resource Sharing: Threads within the same process share the same memory space, allowing efficient sharing of data and resources. This avoids the need for inter-process communication (IPC) mechanisms, which can be slower and more complex. Multithreading enables seamless data sharing between threads, making it easier to coordinate and exchange information.\n",
        "\n",
        "4. Modularity: Multithreading allows breaking down a complex task into smaller, more manageable units of work. Each unit can be executed in a separate thread, making the code modular and easier to understand and maintain. It simplifies the design and implementation of complex applications by dividing them into smaller, independent parts.\n",
        "\n",
        "Disadvantages of Multithreading:\n",
        "\n",
        "1. Complexity: Multithreading introduces complexity to program design and development. Coordinating and synchronizing threads, managing shared resources, and avoiding race conditions require careful programming techniques. Incorrect thread synchronization can lead to subtle bugs that are challenging to debug and reproduce.\n",
        "\n",
        "2. Concurrency Issues: Multithreading can introduce concurrency issues such as race conditions, deadlocks, and livelocks. Race conditions occur when multiple threads access and modify shared data simultaneously, leading to unpredictable results. Deadlocks occur when threads wait indefinitely for resources that are held by other threads, causing a program to hang. Livelocks occur when threads are unable to make progress due to continuous interaction without achieving the desired outcome.\n",
        "\n",
        "3. Increased Memory Usage: Each thread has its own stack, which consumes memory resources. Creating a large number of threads or using them for tasks with minimal benefits can result in excessive memory consumption. This can potentially lead to decreased performance or even out-of-memory errors.\n",
        "\n",
        "4. Limited CPU Utilization: In certain scenarios, such as CPU-bound tasks in Python due to the Global Interpreter Lock (GIL), multithreading might not provide significant performance gains. The GIL restricts true parallel execution of threads in Python, limiting the utilization of multiple CPU cores for CPU-bound tasks.\n",
        "\n",
        "5. Debugging and Testing: Multithreaded programs can be more challenging to debug and test compared to single-threaded programs. Reproducing and diagnosing issues related to thread synchronization, race conditions, and other concurrency problems can be complex. Proper testing and debugging techniques, including thorough code review and testing strategies, are required to ensure the correctness and reliability of multithreaded programs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbiySWCQPrIe"
      },
      "source": [
        "## **Q6. Explain deadlocks and race conditions.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7lErazYmnDc"
      },
      "source": [
        "**Deadlock:**\n",
        "A deadlock is a situation that occurs in concurrent programming when two or more threads are waiting indefinitely for each other to release resources, resulting in a state where none of the threads can proceed. In other words, each thread is holding a resource that another thread needs while waiting for a resource held by that other thread. As a result, the threads become deadlocked, unable to make progress.\n",
        "\n",
        "Key conditions for a deadlock to occur, known as the Coffman conditions, are:\n",
        "\n",
        "1. Mutual Exclusion: The resources involved are non-shareable, meaning only one thread can access a resource at a time.\n",
        "2. Hold and Wait: Threads hold resources while waiting to acquire additional resources.\n",
        "3. No Preemption: Resources cannot be forcibly taken from a thread; they can only be released voluntarily.\n",
        "4. Circular Wait: A circular chain of threads exists, where each thread is waiting for a resource held by the next thread in the chain.\n",
        "\n",
        "Deadlocks can cause the entire program to freeze or hang, leading to unresponsiveness or termination. Avoiding deadlocks involves careful resource management, proper ordering of resource acquisition, and utilizing synchronization mechanisms like locks, semaphores, or condition variables.\n",
        "\n",
        "**Race Condition:**\n",
        "A race condition is a flaw that occurs in concurrent programming when the outcome of the program depends on the relative timing or interleaving of multiple threads. It arises when two or more threads access shared data or resources simultaneously, and the final result depends on the order of execution.\n",
        "\n",
        "Race conditions can lead to incorrect or unpredictable results because the threads may produce unexpected output or modify shared data in an unintended manner. The outcome of a race condition is non-deterministic, meaning it may vary each time the program runs.\n",
        "\n",
        "Race conditions typically occur when the following conditions are met:\n",
        "\n",
        "1. Shared Data: Multiple threads access and modify the same shared data or resources.\n",
        "2. Unsynchronized Access: There is no proper synchronization mechanism in place to coordinate the access to shared data.\n",
        "3. Interleaved Execution: The threads are scheduled and executed in an interleaved or unpredictable manner.\n",
        "To prevent race conditions, synchronization techniques like locks, mutexes, or atomic operations are used to ensure that only one thread can access and modify the shared data at a time. Proper synchronization guarantees mutual exclusion and preserves the consistency of shared data.\n",
        "\n",
        "Race conditions and deadlocks are common concurrency issues that can cause problems in multithreaded programs. Understanding these concepts and applying proper synchronization techniques are crucial to avoid such issues and ensure the correctness and reliability of concurrent applications.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMQaI9cXK/oY5zfxpYAs+7R",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
