{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Explain the following with an example:\n",
    "\n",
    "1. **Artificial Intelligence**\n",
    "\n",
    "2. **Machine Learning**\n",
    "\n",
    "3. **Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Artificial Intelligence (AI):**\n",
    "    \n",
    "    Artificial Intelligence is a broad field of computer science that focuses on creating systems and machines capable of performing tasks that typically require human intelligence. AI encompasses a wide range of techniques and technologies. It can be categorized into two main types:\n",
    "\n",
    "    - **Narrow/Weak AI:** This type of AI is designed for a specific task or a narrow set of tasks. It can't perform tasks outside its predefined domain. A common example of narrow AI is voice assistants like Apple's Siri or Amazon's Alexa. These systems can answer questions and perform tasks like setting reminders or playing music but can't perform tasks beyond their programming.\n",
    "\n",
    "    - **General/Strong AI:** General AI aims to create machines that possess human-like intelligence and can perform any intellectual task that a human can do. We do not have true General AI as of my knowledge cutoff date, and it remains a topic of research and speculation.\n",
    "\n",
    "2. **Machine Learning (ML):**\n",
    "    \n",
    "    Machine Learning is a subset of AI that involves the development of algorithms and models that enable computers to learn from and make predictions or decisions based on data. Instead of being explicitly programmed to perform a task, a machine learning system uses data to improve its performance over time. There are various types of machine learning, including:\n",
    "\n",
    "    - **Supervised Learning:** In supervised learning, the algorithm is trained on a labeled dataset, where the input data is paired with the corresponding correct output. For example, a spam email filter is trained on a dataset of emails labeled as \"spam\" or \"not spam\" to learn how to classify new emails.\n",
    "\n",
    "    - **Unsupervised Learning:** Unsupervised learning involves finding patterns and structures in unlabeled data. An example would be clustering similar documents or grouping similar customer profiles in marketing.\n",
    "\n",
    "    - **Reinforcement Learning:** In reinforcement learning, agents learn to make sequences of decisions to maximize a reward. It's often used in applications like game playing (e.g., AlphaGo) and robotics.\n",
    "\n",
    "3. **Deep Learning:**\n",
    "    \n",
    "    Deep Learning is a subset of machine learning that focuses on using neural networks with multiple layers (deep neural networks) to model and solve complex problems. Deep learning has gained prominence in recent years due to its ability to handle large amounts of data and its success in tasks like image and speech recognition. Examples include:\n",
    "\n",
    "    - **Image Recognition:** Convolutional Neural Networks (CNNs) are used for image recognition. For instance, systems like Facebook's automatic image tagging or self-driving cars use deep learning to identify objects on the road.\n",
    "\n",
    "    - **Natural Language Processing (NLP):** Recurrent Neural Networks (RNNs) and Transformer models are used for tasks like language translation, sentiment analysis, and chatbots. Google's BERT model is an example of a Transformer-based NLP model.\n",
    "\n",
    "    - **Speech Recognition:** Deep learning is used in applications like voice assistants (e.g., Siri or Google Assistant) to convert spoken language into text and understand voice commands.\n",
    "\n",
    "    - Deep learning models are particularly powerful because they can automatically learn hierarchical representations from data, making them well-suited for tasks that involve complex patterns and large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2- What is supervised learning? List some examples of supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning is a type of machine learning where an algorithm learns from a labeled dataset, which means the algorithm is provided with input data along with corresponding output labels. The goal of supervised learning is to learn a mapping from input to output so that the algorithm can make predictions or classifications when given new, unseen data.\n",
    "\n",
    "In supervised learning, the algorithm is trained on historical data with known outcomes, allowing it to generalize and make predictions on new, unseen data. The key steps in supervised learning include data collection, data labeling, model training, and evaluation. The algorithm iteratively adjusts its internal parameters to minimize the difference between its predictions and the true labels in the training data.\n",
    "\n",
    "Here are some examples of supervised learning applications:\n",
    "\n",
    "1. **Image Classification:** Given a dataset of images with labels (e.g., cats or dogs), a supervised learning algorithm can be trained to classify new images into these categories.\n",
    "\n",
    "2. **Spam Email Detection:** In this case, the algorithm is trained on a labeled dataset of emails that are categorized as \"spam\" or \"not spam.\" It can then be used to classify incoming emails as spam or not.\n",
    "\n",
    "3. **Handwriting Recognition:** Supervised learning can be used to recognize handwritten characters or digits. For instance, it can be applied to the recognition of handwritten digits on checks.\n",
    "\n",
    "4. **Medical Diagnosis:** Using historical medical data with labeled patient outcomes, supervised learning algorithms can predict diseases, such as diabetes, based on patient characteristics.\n",
    "\n",
    "5. **Customer Churn Prediction:** In business, companies can use supervised learning to predict whether a customer is likely to churn (leave) based on their usage patterns, demographics, and interactions with the company.\n",
    "\n",
    "6. **Sentiment Analysis:** Analyzing social media posts or product reviews to determine whether the sentiment expressed is positive, negative, or neutral.\n",
    "\n",
    "7. **Language Translation:** In machine translation, parallel texts (text in one language and its translation in another) are used for training the model to translate from one language to another.\n",
    "\n",
    "8. **Stock Price Prediction:** Using historical stock price data, a supervised learning model can predict future stock prices.\n",
    "\n",
    "9. **Credit Scoring:** Banks and financial institutions use supervised learning to assess the creditworthiness of individuals by analyzing their financial history and personal information.\n",
    "\n",
    "10. **Weather Forecasting:** Meteorologists use supervised learning algorithms to predict weather conditions based on historical weather data and various environmental factors.\n",
    "\n",
    "Supervised learning is widely used in various domains because it's effective for tasks where there is a clear relationship between input data and desired outputs. It's a fundamental and widely applied machine learning paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3- What is unsupervised learning? List some examples of unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning is a type of machine learning where an algorithm is trained on data without explicit supervision in the form of labeled output. In unsupervised learning, the algorithm explores the underlying structure or patterns in the data without knowing the correct answers in advance. The primary goal is often to discover hidden structures, relationships, or groupings within the data.\n",
    "\n",
    "Here are some examples of unsupervised learning applications:\n",
    "\n",
    "1. **Clustering:** Clustering is a common unsupervised learning task. Algorithms like k-means clustering or hierarchical clustering group data points into clusters based on their similarity. For example:\n",
    "\n",
    "    - **Customer Segmentation:** Grouping customers with similar purchasing behavior for targeted marketing.\n",
    "    - **Document Clustering:** Organizing unstructured text documents into topics or categories.\n",
    "\n",
    "2. **Dimensionality Reduction:** Dimensionality reduction techniques like Principal Component Analysis (PCA) or t-SNE are used to reduce the number of features in a dataset while preserving its essential characteristics. This is useful for:\n",
    "\n",
    "    - **Data Visualization:** Reducing high-dimensional data to 2D or 3D for visualization purposes.\n",
    "    - **Feature Engineering:** Reducing the complexity of data before applying other machine learning algorithms.\n",
    "3. **Anomaly Detection:** Unsupervised learning can be used to identify anomalies or outliers in a dataset. This is crucial for applications like:\n",
    "\n",
    "    - **Fraud Detection:** Detecting unusual patterns in financial transactions.\n",
    "    - **Network Security:** Identifying unusual network traffic patterns that may indicate cyberattacks.\n",
    "4. **Density Estimation:** Unsupervised learning can be used to estimate the probability density function of a dataset. Gaussian Mixture Models (GMM) is an example. This is applied in:\n",
    "\n",
    "    - **Image Segmentation:** Dividing an image into regions with similar pixel intensities.\n",
    "    - **Speech Recognition:** Modeling the probability distribution of acoustic features.\n",
    "5. **Topic Modeling:** Topic modeling techniques, such as Latent Dirichlet Allocation (LDA), are used to discover themes or topics within a collection of documents. This is commonly used in:\n",
    "    - **Text Analysis:** Identifying topics in large text corpora, such as news articles or social media posts.\n",
    "Recommendation Systems: Collaborative filtering and matrix factorization are unsupervised techniques used in recommendation systems to suggest products, movies, or content to users based on their behavior and preferences.\n",
    "\n",
    "6. **Data Compression:** Unsupervised learning is utilized for data compression or data representation methods such as autoencoders. These are used in:\n",
    "\n",
    "    - **Image and Video Compression:** Reducing the size of image or video files without significant loss of quality.\n",
    "    - **Denoising:** Removing noise from data or images.\n",
    "\n",
    "Unsupervised learning is valuable for tasks where the data lacks clear labels, and the goal is to explore and extract meaningful information from the data itself. It is often used for exploratory data analysis, data preprocessing, and finding hidden patterns in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: What is the difference between AI, ML, DL and DS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI (Artificial Intelligence), ML (Machine Learning), DL (Deep Learning), and DS (Data Science) are related but distinct fields within the broader domain of computer science and data analysis. Here are the key differences between these terms:\n",
    "\n",
    "1. **Artificial Intelligence (AI):**\n",
    "\n",
    "    - **Definition:** AI is the overarching field that focuses on creating systems or machines that can perform tasks requiring human-like intelligence, such as reasoning, problem-solving, learning, perception, and language understanding.\n",
    "    - **Scope:** AI encompasses a wide range of techniques, including machine learning and deep learning, as well as other methods like rule-based systems and expert systems.\n",
    "    - **Examples:** AI can include chatbots, robotics, natural language understanding, game playing (e.g., chess or Go), and autonomous vehicles.\n",
    "\n",
    "2. **Machine Learning (ML):**\n",
    "\n",
    "    - **Definition:** ML is a subset of AI that specifically deals with the development of algorithms and models that can learn from data and make predictions or decisions without being explicitly programmed.\n",
    "    - **Approach:** ML algorithms learn from labeled data, make predictions, and improve their performance over time through the process of training.\n",
    "    - **Examples:** Supervised learning, unsupervised learning, reinforcement learning, and various applications like image recognition and recommendation systems fall under ML.\n",
    "\n",
    "3. **Deep Learning (DL):**\n",
    "\n",
    "    - **Definition:** Deep Learning is a subfield of ML that uses neural networks with multiple layers (deep neural networks) to model and solve complex problems, particularly those involving large datasets and intricate patterns.\n",
    "    - **Architecture:** DL relies on deep neural networks that automatically learn hierarchical representations of data, making it suitable for tasks such as image and speech recognition.\n",
    "    - **Examples:** Convolutional Neural Networks (CNNs) for image analysis, Recurrent Neural Networks (RNNs) for sequential data, and Transformer models for natural language processing are common examples of DL.\n",
    "\n",
    "4. **Data Science (DS):**\n",
    "\n",
    "    - **Definition:** Data Science is a multidisciplinary field that involves the use of various techniques and tools to extract insights, knowledge, and actionable information from data. It often includes data collection, cleaning, analysis, and visualization.\n",
    "    - **Role:** Data scientists use statistical analysis, machine learning, data engineering, and domain expertise to solve complex data-related problems.\n",
    "    - **Examples:** Data science is applied in a wide range of domains, including business analytics, healthcare, finance, and research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: what are the main differences between supervised, unsupervised and semi-supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised, unsupervised, and semi-supervised learning are three different approaches to machine learning, each with distinct characteristics. Here are the main differences between them:\n",
    "\n",
    "1. **Supervised Learning:**\n",
    "    - Labelled Data: In supervised learning, the algorithm is trained on a labeled dataset, where both input data and their corresponding correct output (labels) are provided.\n",
    "    - Goal: The primary goal of supervised learning is to learn a mapping from input to output, so the algorithm can make predictions or classifications on new, unseen data.\n",
    "    - Examples: Image classification, spam email detection, and handwriting recognition are examples of supervised learning tasks.\n",
    "        \n",
    "2. **Unsupervised Learning:**\n",
    "    - Unlabeled Data: Unsupervised learning operates on unlabeled data, meaning the algorithm doesn't have access to the correct output labels during training.\n",
    "    - Goal: The primary goal is to explore the underlying structure or patterns in the data, which may involve clustering data points or reducing dimensionality to discover hidden relationships.\n",
    "    - Examples: Clustering similar customer groups, reducing data dimensionality for visualization, and anomaly detection are common unsupervised learning tasks.\n",
    "\n",
    "3. **Semi-Supervised Learning:**\n",
    "    - Mixed Data: Semi-supervised learning is a hybrid approach that combines both labeled and unlabeled data for training. Typically, the ratio of labeled to unlabeled data is small.\n",
    "    - Goal: Semi-supervised learning leverages the additional unlabeled data to improve the performance and generalization of models trained on limited labeled data.\n",
    "    - Examples: One common scenario is using a small labeled dataset to train a model and then using a much larger unlabeled dataset to fine-tune the model, which can be particularly beneficial when labeled data is expensive or hard to obtain.\n",
    "    \n",
    "Key differences:\n",
    "\n",
    "- **Data Type:** The primary difference is the type of data used for training. Supervised learning relies on labeled data, unsupervised learning operates on unlabeled data, and semi-supervised learning combines both labeled and unlabeled data.\n",
    "\n",
    "- **Goal:** In supervised learning, the goal is to make precise predictions or classifications, whereas unsupervised learning seeks to uncover patterns and structures in data. Semi-supervised learning aims to enhance the performance of models trained with limited labeled data by leveraging the additional information from unlabeled data.\n",
    "\n",
    "- **Applications:** Supervised learning is commonly used in tasks that require specific predictions or classifications, while unsupervised learning is used for tasks involving data exploration and pattern discovery. Semi-supervised learning is often applied when there's a scarcity of labeled data.\n",
    "\n",
    "- **Data Availability:** In terms of data availability, supervised learning requires a substantial amount of labeled data, unsupervised learning can work with unlabeled data, and semi-supervised learning can be valuable when there's a mix of labeled and unlabeled data available, but the labeled data is limited.\n",
    "\n",
    "Semi-supervised learning is a valuable approach when obtaining large amounts of labeled data is difficult or costly, as it can bridge the gap between the effectiveness of supervised learning and the data exploration capabilities of unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: what is train, test and validation split? Explain the importance of each term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train-test-validation split is a fundamental concept in machine learning and model development. It involves dividing a dataset into three distinct subsets: the training set, the validation set, and the testing set. Each of these subsets serves a specific purpose, and they are crucial for building, tuning, and evaluating machine learning models. Here's an explanation of each term and its importance:\n",
    "\n",
    "1. **Training Set:**\n",
    "\n",
    "    - **Purpose:** The training set is the largest portion of the dataset, and it is used to train the machine learning model. The model learns patterns, relationships, and parameters from this data.\n",
    "    - **Importance:**\n",
    "        - **Model Learning:** This is where the machine learning algorithm learns how to make predictions or classifications based on the provided features.\n",
    "        - **Parameter Tuning:** It allows the model's parameters (weights and biases in neural networks, for example) to be adjusted during training to minimize the difference between its predictions and the true labels in the training data.\n",
    "    - **Common Split Ratio:** Typically, 60-80% of the data is allocated to the training set.\n",
    "\n",
    "2. **Validation Set:**\n",
    "\n",
    "    - **Purpose:** The validation set is used to fine-tune the model and optimize its hyperparameters. It helps assess how well the model generalizes to unseen data.\n",
    "    - **Importance:**\n",
    "        - **Hyperparameter Tuning:** By evaluating the model's performance on the validation set, you can adjust hyperparameters (e.g., learning rates or regularization strengths) to improve model performance without overfitting to the training data.\n",
    "        - **Model Selection:** It helps compare different models and choose the one that performs best on unseen data.\n",
    "    - **Common Split Ratio:** Typically, 10-20% of the data is allocated to the validation set.\n",
    "\n",
    "3. **Testing Set:**\n",
    "\n",
    "    - **Purpose:** The testing set is reserved for evaluating the model's performance after training and hyperparameter tuning. It provides an unbiased estimate of how well the model is expected to perform on new, unseen data.\n",
    "    - **Importance:**\n",
    "        - **Generalization Assessment:** The testing set helps assess the model's ability to generalize to data it hasn't seen during training.\n",
    "        - **Avoiding Overfitting:** It helps ensure that the model has not overfit the training data, where it learns to perform well on the training data but poorly on new data.\n",
    "    - **Common Split Ratio:** Typically, 10-20% of the data is allocated to the testing set.\n",
    "\n",
    "The importance of these subsets can be summarized as follows:\n",
    "\n",
    "- **Training Set:** This is where the model learns from the data and adapts its parameters. It's essential for building a model that can make predictions or classifications.\n",
    "\n",
    "- **Validation Set:** This is used to fine-tune the model's hyperparameters and assess its performance during development. It helps ensure that the model is optimized without overfitting to the training data.\n",
    "\n",
    "- **Testing Set:** The testing set provides an unbiased evaluation of the model's generalization capabilities. It helps determine how well the model is expected to perform on new, unseen data, which is the ultimate goal in most machine learning applications.\n",
    "\n",
    "The separation of data into these subsets is critical for ensuring that machine learning models are trained, validated, and evaluated in a robust and unbiased manner, allowing for accurate assessments of their performance and generalization to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: How can unsupervised learning be used in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning is a powerful technique for anomaly detection because it doesn't rely on labeled data with predefined anomalies. Instead, it identifies anomalies based on deviations from the normal patterns or structures within the data. Here's how unsupervised learning can be used in anomaly detection:\n",
    "\n",
    "1. **Data Preprocessing:**\n",
    "\n",
    "    - Before applying unsupervised learning techniques, it's essential to preprocess the data, which may involve data cleaning, feature scaling, and dimensionality reduction. Preprocessing helps prepare the data for anomaly detection algorithms.\n",
    "\n",
    "2. **Feature Extraction/Reduction:**\n",
    "\n",
    "    - In many cases, high-dimensional data can be reduced to a lower-dimensional representation using techniques like Principal Component Analysis (PCA). This reduces computational complexity and can reveal the underlying structure of the data.\n",
    "\n",
    "3. **Clustering Algorithms:**\n",
    "\n",
    "    - Unsupervised learning techniques, such as clustering algorithms like k-means or DBSCAN, can be applied to group data points into clusters based on their similarity. Anomalies may be identified as data points that do not fit well within any cluster.\n",
    "\n",
    "4. **Density-Based Methods:**\n",
    "\n",
    "    - Algorithms like Local Outlier Factor (LOF) and Isolation Forest are density-based methods that identify anomalies by measuring the local density of data points. Outliers are data points with significantly lower density compared to their neighbors.\n",
    "\n",
    "5. **Distance-Based Methods:**\n",
    "\n",
    "    - Distance-based approaches calculate the similarity or dissimilarity of data points. Anomalies are often detected as data points with unusually large distances from their nearest neighbors.\n",
    "\n",
    "6. **Autoencoders:**\n",
    "\n",
    "    - Autoencoders are a type of neural network used in deep learning for anomaly detection. The model learns to encode data and decode it back to its original form. Anomalies are detected when the reconstruction error is high for specific data points.\n",
    "\n",
    "7. **One-Class SVM:**\n",
    "\n",
    "    - One-Class Support Vector Machines (SVM) is a technique that learns a boundary around the normal data and identifies anomalies as data points lying outside this boundary.\n",
    "\n",
    "8. **Ensemble Methods:**\n",
    "\n",
    "    - Ensemble methods combine multiple anomaly detection algorithms to improve robustness. They can provide more accurate and reliable anomaly detection by aggregating the results of multiple models.\n",
    "\n",
    "9. **Visual Analytics:**\n",
    "\n",
    "    - Visual techniques, such as scatter plots or heatmaps, can be used to visualize the data and highlight anomalies or patterns that stand out visually.\n",
    "\n",
    "10. **Continuous Monitoring:**\n",
    "\n",
    "    - Anomaly detection models can be deployed for continuous monitoring of data streams or real-time systems. When a new data point is observed, it is checked against the learned patterns, and if it deviates significantly, it is flagged as an anomaly.\n",
    "\n",
    "11. **Thresholding:**\n",
    "\n",
    "    - Thresholds can be set to determine what constitutes an anomaly based on model outputs, such as the distance from the cluster center, the reconstruction error, or the SVM score.\n",
    "\n",
    "Unsupervised learning approaches in anomaly detection are particularly useful when the characteristics of anomalies are not well-defined or when it is challenging to obtain labeled data. By learning the normal behavior of the data, these techniques can effectively identify unexpected and potentially harmful deviations, making them valuable in various domains, including fraud detection, network security, and quality control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: List down some commonly used supervised learning algorithms and unsupervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Learning Algorithms:**\n",
    "\n",
    "1. **Linear Regression**: Used for regression tasks to model the relationship between dependent and independent variables as a linear equation.\n",
    "\n",
    "2. **Logistic Regression**: Used for binary and multi-class classification problems, it models the probability of a data point belonging to a specific class.\n",
    "\n",
    "3. **Decision Trees:** They are used for both classification and regression tasks. Decision trees make decisions by splitting data into smaller subsets based on feature values.\n",
    "\n",
    "4. **Random Forest:** An ensemble learning method that combines multiple decision trees to improve accuracy and reduce overfitting.\n",
    "\n",
    "5. **Support Vector Machines (SVM):** Used for classification and regression, SVM finds the optimal hyperplane that best separates data points.\n",
    "\n",
    "6. **k-Nearest Neighbors (k-NN):** A simple classification and regression algorithm that classifies data points based on the majority class among their k-nearest neighbors.\n",
    "\n",
    "7. **Naive Bayes:** A probabilistic classifier based on Bayes' theorem, often used for text classification and spam detection.\n",
    "\n",
    "8. **Neural Networks (Deep Learning):** Multi-layer neural networks, such as feedforward and convolutional neural networks, are used for various tasks, including image and speech recognition.\n",
    "\n",
    "9. **Gradient Boosting Algorithms:** Examples include AdaBoost, Gradient Boosting Machines (GBM), and XGBoost. They create a strong predictive model by combining the predictions of weak models.\n",
    "\n",
    "10. **Linear Discriminant Analysis (LDA):** Used for dimensionality reduction and classification problems, LDA seeks to maximize the separation between classes.\n",
    "\n",
    "**Unsupervised Learning Algorithms:**\n",
    "1. **K-Means Clustering:** A widely used clustering algorithm that groups data points into clusters based on similarity.\n",
    "\n",
    "2. **Hierarchical Clustering:** Builds a tree-like structure of clusters by successively merging or splitting data points based on their similarity.\n",
    "\n",
    "3. **Principal Component Analysis (PCA):** Reduces the dimensionality of data while preserving the most important information, often used for data compression and visualization.\n",
    "\n",
    "4. **Independent Component Analysis (ICA):** Separates a multivariate signal into additive, independent components.\n",
    "\n",
    "5. **Autoencoders:** Neural networks used for dimensionality reduction and data compression by learning efficient representations of the input data.\n",
    "\n",
    "6. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise):** Identifies clusters based on the density of data points, suitable for irregularly shaped clusters.\n",
    "\n",
    "7. **Gaussian Mixture Models (GMM):** Models data as a mixture of multiple Gaussian distributions and is used for clustering and density estimation.\n",
    "\n",
    "8. **Isolation Forest:** Anomaly detection algorithm based on isolating anomalies rather than profiling normal data points.\n",
    "\n",
    "9. **Local Outlier Factor (LOF):** Anomaly detection algorithm that measures the local density of data points to identify outliers.\n",
    "\n",
    "10. **t-Distributed Stochastic Neighbor Embedding (t-SNE):** Used for dimensionality reduction and visualization, particularly effective for visualizing high-dimensional data in lower dimensions.\n",
    "\n",
    "These are just a selection of commonly used algorithms in supervised and unsupervised learning. The choice of algorithm depends on the specific problem, the nature of the data, and the desired outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
